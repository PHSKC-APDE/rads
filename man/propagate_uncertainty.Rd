% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/propagate_uncertainty.R
\name{propagate_uncertainty}
\alias{propagate_uncertainty}
\title{Propagate Uncertainty Between Two Point Estimates using Monte Carlo simulation}
\usage{
propagate_uncertainty(
  ph.estimates,
  comp_mean_col,
  comp_se_col = NULL,
  comp_lower_col = NULL,
  comp_upper_col = NULL,
  ref_mean_col,
  ref_se_col = NULL,
  ref_lower_col = NULL,
  ref_upper_col = NULL,
  contrast_fn = function(x, y) x - y,
  dist = "normal",
  se_scale = "original",
  draws = 10000,
  seed = 98104,
  alpha = 0.05,
  h0_value = NULL,
  use_futures = FALSE,
  pvalue_method = "proportion",
  convergence_check = FALSE,
  convergence_tolerance = 0.05,
  convergence_sample_size = 10
)
}
\arguments{
\item{ph.estimates}{A data.table containing the point estimates and
uncertainty measures}

\item{comp_mean_col}{Character. Column name for the comparator group point
estimates}

\item{comp_se_col}{Character. Column name for the comparator group standard
errors (optional)}

\item{comp_lower_col}{Character. Column name for the comparator group lower
CI (optional)}

\item{comp_upper_col}{Character. Column name for the comparator group upper
CI (optional)}

\item{ref_mean_col}{Character. Column name for the reference group point
estimates}

\item{ref_se_col}{Character. Column name for the reference group standard
errors (optional)}

\item{ref_lower_col}{Character. Column name for the reference group lower CI
(optional)}

\item{ref_upper_col}{Character. Column name for the reference group upper CI
(optional)}

\item{contrast_fn}{Function. Function to calculate contrast between groups.
Common options include:
\itemize{
\item \code{function(x, y) x - y} for differences (default)
\item \code{function(x, y) x / y} for ratios
\item \code{function(x, y) 100 * (x - y) / y} for percent differences
\item \code{function(x, y) log(x / y)} for log ratios
}}

\item{dist}{Character. Distribution assumption for the INPUT estimates (not
the contrast):
\itemize{
\item \code{"normal"}: Use normal distribution. Appropriate when input estimates can
theoretically take any real value, including: means, differences, proportions,
log-odds, log-hazard ratios, and other log-transformed coefficients (default)
\item \code{"lognormal"}: Use lognormal distribution. Appropriate when input estimates
are strictly positive and right-skewed, such as: exponentiated coefficients
(odds ratios, hazard ratios, rate ratios), raw rates, or counts
Note: This refers to the sampling distribution of your INPUT estimates,
not the type of contrast function you're calculating.
}}

\item{se_scale}{Character. Scale that standard errors are reported on:
\itemize{
\item \code{"original"}: Standard errors are on the same scale as the point estimates
(default)
\item \code{"log"}: Standard errors are on the log scale (sometimes used with
exponentiated estimates)
}}

\item{draws}{Integer. Number of Monte Carlo draws per observation}

\item{seed}{Integer. Random seed for reproducibility. Default \code{seed = 98104}}

\item{alpha}{Numeric. Alpha level for confidence intervals (default 0.05 for
95\% CI)}

\item{h0_value}{Numeric. Value for null hypothesis testing. Default
\code{h0_value = NULL} uses empirical detection (0 for differences, 1 for ratios).
Set explicitly for custom tests (e.g., \code{h0_value = 10} to test if difference
does not equal 10).}

\item{use_futures}{Logical. Whether to use future.apply for parallelization}

\item{pvalue_method}{Character. Method for p-value calculation:
\itemize{
\item "proportion": Empirical p-value based on proportion of draws crossing the
null hypothesis (robust to non-normal distributions, recommended for most
cases) (default)
\item "ttest": Traditional t-test that assumes normality (faster but flawed for
skewed distributions)
}}

\item{convergence_check}{Logical. Whether to assess if Monte Carlo simulation
has converged (recommended for final analyses or if you have time to spare)}

\item{convergence_tolerance}{Numeric. Maximum acceptable relative change
between batches to consider "converged" (default 0.05 = 5\%)}

\item{convergence_sample_size}{Integer. Number of randomly selected rows to
test for convergence (default 10 for efficiency)}
}
\value{
A data.table with original columns plus:
\itemize{
\item \code{contrast}: Mean of contrast values
\item \code{contrast_se}: Standard error of contrast
\item \code{contrast_lower}: Lower confidence interval
\item \code{contrast_upper}: Upper confidence interval
\item \code{contrast_pvalue}: P-value for null hypothesis test
}
}
\description{
Propagates uncertainty when calculating contrasts (differences, ratios, etc.)
between two point estimates by using Monte Carlo simulation. This approach is
needed when assumptions of the normal approximation do not hold. Relevant
examples include exponentiated estimates from logistics or Poisson models, or
when confidence intervals are calculated using specialized methods like the
\href{https://wonder.cdc.gov/controller/pdf/FayFeuerConfidenceIntervals.pdf}{Fay-Feuer}
method (which is used for age-standardized rates). Basically, unless
you have point estimates and uncertainty from a linear model of from simple
means and proportions, you should probably use this function rather than
traditional mathematical methods for error propagation that assume normality.
}
\details{
The function works by generating random draws from the uncertainty distributions
of both groups, applying the contrast function, and summarizing the resulting
empirical distribution.

\strong{Standard Errors vs Confidence Intervals}
If both are provided, standard errors take precedence with a warning. HOWEVER,
there are times when you will want to purposefully NOT provide the standard
error so the function will be fully dependent upon the confidence intervals.
This is appropriate when confidence intervals are calculated directly and the
standard error is an approximation at best (e.g., the Fay-Feuer method used
with age-standardized rates).

\strong{Distribution Choice:}
Use "normal" for most estimates including means, proportions, differences, and
log-transformed values. Use "lognormal" for strictly positive measures like
rates, ratios, or counts where the sampling distribution is right-skewed.

#' \strong{Distribution Choice:}
Choose based on the ORIGINAL INPUT estimates you're comparing, not the contrast:

Use "normal" when your estimates:
\itemize{
\item Can theoretically be negative (means, differences, log-coefficients)
\item Are approximately symmetric around their true value
\item Come from linear models or are log-transformed parameters
}

Use "lognormal" when your estimates:
\itemize{
\item Must be positive (rates, counts, exponentiated coefficients)
\item Have right-skewed sampling distributions
\item Come from models where uncertainty was calculated on the original scale
}

Examples
\itemize{
\item Comparing two log-odds ratios → use "normal"
\item Comparing two odds ratios → use "lognormal"
\item Comparing two mortality rates (deaths per 100,000) → use "lognormal"
\item Comparing two risk differences → use "normal"
\item Comparing two prevalences (e.g., 0.15 vs 0.20) → use "normal"
(proportions are bounded but typically analyzed on original scale)
}

\strong{Standard Error Scale:}
Most standard errors are reported on the "original" scale. Use "log" scale ONLY
when you have standard errors that were calculated on the log scale (uncommon,
but sometimes seen with certain modeling approaches).

\strong{Convergence Checking:}
Monte Carlo methods require sufficient draws for stable results. The convergence
check examines whether estimates stabilize as more draws are added. If convergence
fails, increase the number of draws. This is particularly important for p-values
and when precise estimates are needed for smaller populations.

\strong{Null Hypothesis Testing:}
By default, the function tries to automatically detects the correct null hypothesis
value, e.g., 0 for differences and 1 for ratios. You can override this by setting
\code{h0_value}.
}
\examples{
\dontrun{
library(data.table)

# Example with normal distribution (differences)
dt <- data.table(
  location = c("A", "B", "C"),
  comp_mean = c(10.5, 15.2, 8.7),
  comp_se = c(1.2, 1.8, 0.9),
  ref_mean = c(8.3, 12.1, 9.2),
  ref_se = c(1.0, 1.5, 1.1)
)

result <- propagate_uncertainty(
  ph.estimates = dt,
  comp_mean_col = "comp_mean",
  comp_se_col = "comp_se",
  ref_mean_col = "ref_mean",
  ref_se_col = "ref_se",
  draws = 10000
)

# Example with ratios and confidence intervals
dt_ratios <- data.table(
  outcome = c("Death", "Hospitalization"),
  comp_rate = c(1.5, 3.2),
  comp_lower = c(1.2, 2.8),
  comp_upper = c(1.9, 3.7),
  ref_rate = c(1.0, 2.1),
  ref_lower = c(0.8, 1.8),
  ref_upper = c(1.3, 2.5)
)

result_ratios <- propagate_uncertainty(
  ph.estimates = dt_ratios,
  comp_mean_col = "comp_rate",
  comp_lower_col = "comp_lower",
  comp_upper_col = "comp_upper",
  ref_mean_col = "ref_rate",
  ref_lower_col = "ref_lower",
  ref_upper_col = "ref_upper",
  contrast_fn = function(x, y) x / y,
  dist = "lognormal",
  draws = 10000
)

# Example with custom null hypothesis value
# Testing that the ratio of x to y != 2
result_custom <- propagate_uncertainty(
  ph.estimates = dt,
  comp_mean_col = "comp_mean",
  comp_se_col = "comp_se",
  ref_mean_col = "ref_mean",
  ref_se_col = "ref_se",
  contrast_fn = function(x, y) x / y,
  h0_value = 2,
  draws = 10000
)

}

}
\seealso{
\code{\link[=multi_t_test]{multi_t_test()}} for comparing multiple groups against a
reference group when estimates have symmetric confidence intervals and
normality can be reasonably assumed.
}
\keyword{monte-carlo}
\keyword{propagation}
\keyword{statistics}
\keyword{uncertainty}
