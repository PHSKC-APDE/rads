---
title: "propagate_uncertainty()"
format: gfm
prefer-html: false
editor: visual
---

# Introduction

When comparing health indicators between populations or time periods, we often need to calculate differences or ratios between estimates while accounting for their uncertainty. For example, you might want to know whether the life expectancy in Smallville is significantly different from that in Megalopolis. Or perhaps you want to calculate the ratio of age-adjusted mortality rates between two demographic groups.

The process of combining uncertainties when performing mathematical operations is called **uncertainty propagation** or **error propagation**. While simple formulas exist for basic cases, they make assumptions that often don't hold for common public health indicators. The `propagate_uncertainty()` function provides a robust Monte Carlo approach that works even when traditional methods fail.

This vignette will walk you through when and how to propagate uncertainty, starting with the traditional mathematical approaches and then showing when and why you need the more flexible Monte Carlo method.

```{r}
#| warning: false
#| message: false
library(rads)
library(data.table)
library(ggplot2)
```

```{r}
#| echo: false
pretty_kable <- function(dt) {
  knitr::kable(dt, format = 'markdown')
}
```

# When Traditional Methods Work (and When They Don't)

## Traditional Error Propagation Formulas

For simple cases, we can use familiar mathematical formulas to propagate uncertainty. These work well when estimates follow normal distributions and have symmetric confidence intervals.

**For differences (X - Y):** $$SE_{difference} = \sqrt{SE_X^2 + SE_Y^2}$$

**For ratios (X / Y):** $$SE_{ratio} = \frac{X}{Y} \times \sqrt{\left(\frac{SE_X}{X}\right)^2 + \left(\frac{SE_Y}{Y}\right)^2}$$

These formulas assume that X and Y are independent and normally distributed. Let's see when this works well:

```{r}
# Example: Comparing simple means from two surveys
# These would typically have symmetric, normal-like confidence intervals
smallville_mean <- 68.5  # Mean age
smallville_se <- 2.1
megalopolis_mean <- 71.2
megalopolis_se <- 1.8

# Traditional formula for difference
diff_traditional <- smallville_mean - megalopolis_mean
se_diff_traditional <- sqrt(smallville_se^2 + megalopolis_se^2)
ci_lower_traditional <- diff_traditional - 1.96 * se_diff_traditional
ci_upper_traditional <- diff_traditional + 1.96 * se_diff_traditional

print(paste0("Traditional method - Difference: ", round(diff_traditional, 2),
            " 95% CI: (", round(ci_lower_traditional, 2), ", ", round(ci_upper_traditional, 2), ")"))
```

## When Traditional Methods Fail

Traditional formulas break down when dealing with:

### 1. Exponentiated Results from Regression Models

When you have odds ratios, rates ratios, or hazard ratios from logistic or Poisson regression, the confidence intervals are calculated on the log scale and then exponentiated. This creates asymmetric confidence intervals on the original scale.

### 2. Age-Adjusted Rates

The confidence intervals for age-adjusted rates are often asymmetric because they:

-   Combine rates from different age groups with varying sample sizes
-   Use methods like [Fay-Feuer](https://wonder.cdc.gov/controller/pdf/FayFeuerConfidenceIntervals.pdf) that account for the Poisson nature of count data
-   Reflect skewed distributions, especially when dealing with rare events

### 3. Life Expectancy

Life expectancy confidence intervals are often asymmetric because they:

-   Come from complex life table calculations that are inherently non-linear
-   Can't go below zero but have no strict upper limit
-   Are sensitive to mortality rates at young ages, where small changes can have large effects

### 4. Any Indicator with Asymmetric Confidence Intervals

If your confidence intervals aren't roughly symmetric around the point estimate, traditional formulas will give incorrect results.

## A Better Approach: Monte Carlo Simulation

For cases described above, we need a method that doesn't assume normality or symmetry. Monte Carlo simulation works by:

1.  **Generating thousands of random draws** from the uncertainty distributions of both estimates
2.  **Applying your operation** (difference, ratio, etc.) to each pair of draws
3.  **Summarizing the resulting distribution** to get the final estimate and confidence interval

This approach is valid regardless of the underlying distributions and automatically captures the correct uncertainty propagation.

# Visualizing the Monte Carlo Approach

Let's see how Monte Carlo simulation works by comparing it with the familiar case of estimates from normal distributions. These are condition under which traditional parametric methods work.

Define the age distributions

```{r}
smallville_le <- 34.3
smallville_se <- 0.2

megalopolis_le <- 37.2
megalopolis_se <- 0.15
```

Traditional calculation of the age difference

```{r}
traditional_diff <- megalopolis_le - smallville_le
traditional_se <- sqrt(smallville_se^2 + megalopolis_se^2)
traditional_lower <- traditional_diff - 1.96 * traditional_se
traditional_upper <- traditional_diff + 1.96 * traditional_se
```

Monte Carlo simulation of normal distributions based on summary statistics

```{r}
set.seed(98104)
n_draws <- 10000
smallville_draws <- rnorm(n_draws, smallville_le, smallville_se)
megalopolis_draws <- rnorm(n_draws, megalopolis_le, megalopolis_se)
difference_draws <- megalopolis_draws - smallville_draws
```

Summarize Monte Carlo simulations

```{r}
mc_diff <- mean(difference_draws)
mc_lower <- quantile(difference_draws, 0.025)
mc_upper <- quantile(difference_draws, 0.975)
```

Visualize the Monte Carlo simulations

```{r}
#| fig.width: 12
#| fig.height: 5
#| echo: false
#| dev: "png"
#| dpi: 300
# Order properly
plot_data <- data.table(
  value = c(megalopolis_draws, smallville_draws, difference_draws),
  distribution = factor(rep(c("Megalopolis", "Smallville", "Difference"), each = 10000),
                       levels = c("Megalopolis", "Smallville", "Difference"))
)

# Calculate summary stats for each distribution
megalopolis_mean <- mean(megalopolis_draws)
megalopolis_ci_low <- quantile(megalopolis_draws, 0.025)
megalopolis_ci_high <- quantile(megalopolis_draws, 0.975)

smallville_mean <- mean(smallville_draws)
smallville_ci_low <- quantile(smallville_draws, 0.025)
smallville_ci_high <- quantile(smallville_draws, 0.975)

# Create labels for each panel
labels_data <- data.table(
  distribution = factor(c("Megalopolis LE", "Smallville LE", "Difference"),
                       levels = c("Megalopolis LE", "Smallville LE", "Difference")),
  label = c(
    paste0("Mean: ", round2(megalopolis_mean, 2), "\nCI: (", round2(megalopolis_ci_low, 2), ", ", round2(megalopolis_ci_high, 2), ")"),
    paste0("Mean: ", round2(smallville_mean, 2), "\nCI: (", round2(smallville_ci_low, 2), ", ", round2(smallville_ci_high, 2), ")"),
    paste0("Mean: ", round2(mc_diff, 3), "\nCI: (", round2(mc_lower, 3), ", ", round2(mc_upper, 3), ")")
  )
)

p1 <- ggplot(plot_data, aes(x = value, fill = distribution)) +
  geom_histogram(alpha = 0.7, bins = 100, color = "white") +
  facet_wrap(~distribution, ncol = 3, scales = "free_x") +  # Free x-axis, shared y-axis
  labs(title = "Monte Carlo Simulation: Normal Case",
       subtitle = "Comparing Life Expectancy Between Cities",
       x = "Value", y = "Count") +
  theme_minimal() +
  theme(legend.position = "none", 
        panel.grid = element_blank()) +
  geom_text(data = labels_data, aes(label = label), 
            x = Inf, y = Inf, hjust = 1.1, vjust = 1.1, 
            size = 3, inherit.aes = FALSE)

print(p1)
```

Compare the results

```{r}
#| echo: false
pretty_kable(data.table(` ` = c('Difference', 'Lower', 'Upper'), 
                        Traditional = round2(c(traditional_diff, traditional_lower, traditional_upper), 3), 
                        `Monte Carlo` = round2(c(mc_diff, mc_lower, mc_upper), 3)))
```

As you can see, when the underlying distributions are normal, Monte Carlo and traditional methods give nearly identical results.

# The `propagate_uncertainty()` Function

The `propagate_uncertainty()` function automates this Monte Carlo approach, allowing you to apply it to estimates in data.tables.

## Function Parameters

**Data and Column Specifications:**

-   `ph.estimates`: Your data.table/data.frame with point estimates and uncertainty measures
-   `comp_mean_col`: Column name for comparator group point estimates\
-   `ref_mean_col`: Column name for reference group point estimates
-   `comp_se_col` / `ref_se_col`: Standard error columns (when provided, used preferentially over the CI)
-   `comp_lower_col` & `comp_upper_col` / `ref_lower_col` & `ref_upper_col`: Confidence interval columns

**Commonly Modified Parameters:**

-   `contrast_fn`: Function defining your operation. Default: `function(x, y) x - y`
-   `dist`: Distribution assumption - `"normal"` or `"lognormal"`. Default: `"normal"`
-   `draws`: Number of Monte Carlo draws. Default: `10,000`

**Infrequently Modified Parameters:**

-   `alpha`: Significance level for confidence intervals. Default: `0.05`\
-   `convergence_check`: Whether to assess Monte Carlo convergence. Default: `FALSE`
-   `h0_value`: Null hypothesis value for testing. Default: auto-detected
-   `pvalue_method`: `"proportion"` (robust) or `"ttest"` (assumes normality). Default: `"proportion"`
-   `use_futures`: Enable parallel processing for large datasets. Default: `FALSE`
-   `seed`: Random seed for reproducibility. Default: `98104`
-   `se_scale`: Whether standard errors are on `"original"` or `"log"` scale. Default: `"original"`

## :rotating_light: Critical Parameters: `contrast_fn` and `dist`

### Choosing the Contrast Function (`contrast_fn`)

You can provide whatever contrast function you desire. For your convenience, here are the ones you'll most likely want to use.

```{r}
# Differences (default)
contrast_fn = function(x, y) x - y

# Ratios  
contrast_fn = function(x, y) x / y

# Percent differences
contrast_fn = function(x, y) 100 * (x - y) / y

# Log ratios
contrast_fn = function(x, y) log(x / y)
```

### Choosing the Distribution (`dist`)

**Use `dist = "normal"` when `comp_mean_col` and `ref_mean_col`:**

-   Can theoretically be negative (means, differences, log-coefficients)
-   Are approximately symmetric around their true value\
-   Come from linear models or are simple means or proportions

**Use `dist = "lognormal"` when `comp_mean_col` and `ref_mean_col`:**

-   Must be positive (rates, counts, exponentiated coefficients)
-   Have right-skewed sampling distributions
-   Have asymmetric confidence intervals

# Examples: Basic Usage

## Example 1: Comparing Life Expectancy with Standard Errors

Let's compare life expectancy between Smallville and Megalopolis using the `propagate_uncertainty()` function:

```{r}
#| warning: false
#| message: false
# Create example data
life_expectancy_data <- data.table(
  city_comparison = "Megalopolis vs Smallville",
  megalopolis_le = 80.2,
  megalopolis_se = 0.15,
  smallville_le = 79.8, 
  smallville_se = 0.20
)

# Calculate the difference using propagate_uncertainty
le_result <- propagate_uncertainty(
  ph.estimates = life_expectancy_data,
  comp_mean_col = "megalopolis_le",      # Megalopolis is comparator
  comp_se_col = "megalopolis_se",
  ref_mean_col = "smallville_le",        # Smallville is reference  
  ref_se_col = "smallville_se",
  contrast_fn = function(x, y) x - y,    # Calculate difference
  dist = "normal",                       # Life expectancy can use normal
  draws = 10000,
  seed = 98104
)
```

```{r}
#| echo: false
le_result[, c("contrast", "contrast_lower", "contrast_upper") := lapply(.SD, round2, 2), .SDcols = c("contrast", "contrast_lower", "contrast_upper")]
le_result[, c("contrast_se", "contrast_pvalue") := lapply(.SD, round2, 3), .SDcols = c("contrast_se", "contrast_pvalue")]
pretty_kable(le_result[, .(city_comparison, contrast, contrast_lower, contrast_upper, 
                           contrast_se, contrast_pvalue)])
```

## Example 2: Comparing Age-Adjusted Mortality Rates with Confidence Intervals

Now let's work with age-adjusted mortality rates that have asymmetric confidence intervals:

```{r}
#| warning: false
#| message: false
# Age-adjusted mortality rates (per 100,000) with asymmetric CIs
mortality_data <- data.table(
  comparison = "City Mortality Comparison", 
  smallville_rate = 652,
  smallville_lower = 618,
  smallville_upper = 689,
  megalopolis_rate = 678,
  megalopolis_lower = 651,
  megalopolis_upper = 708
)

# Calculate the difference - note we're using lognormal distribution
mortality_result <- propagate_uncertainty(
  ph.estimates = mortality_data,
  comp_mean_col = "megalopolis_rate",   # Megalopolis is comparator
  comp_lower_col = "megalopolis_lower", 
  comp_upper_col = "megalopolis_upper",
  ref_mean_col = "smallville_rate",     # Smallville is reference  
  ref_lower_col = "smallville_lower",
  ref_upper_col = "smallville_upper", 
  contrast_fn = function(x, y) x - y,
  dist = "lognormal",                    # Better for rates with asymmetric CIs
  draws = 10000,
  seed = 98104
)
```

```{r}
#| echo: false
mortality_result[, c("contrast", "contrast_lower", "contrast_upper") := lapply(.SD, round2, 2), .SDcols = c("contrast", "contrast_lower", "contrast_upper")]
mortality_result[, c("contrast_se", "contrast_pvalue") := lapply(.SD, round2, 3), .SDcols = c("contrast_se", "contrast_pvalue")]
pretty_kable(mortality_result[, .(comparison, contrast, contrast_lower, contrast_upper, 
                           contrast_se, contrast_pvalue)])
```

## Example 3: Calculating Ratios

Often we want to calculate ratios rather than differences. To do so, just change the `contrast_fn` parameter value.

```{r}
#| warning: false
#| message: false
# Calculate the mortality rate ratio
ratio_result <- propagate_uncertainty(
  ph.estimates = mortality_data,
  comp_mean_col = "megalopolis_rate",    # Megalopolis is comparator
  comp_lower_col = "megalopolis_lower",
  comp_upper_col = "megalopolis_upper", 
  ref_mean_col = "smallville_rate",      # Smallville is reference  
  ref_lower_col = "smallville_lower",
  ref_upper_col = "smallville_upper",
  contrast_fn = function(x, y) x / y,    # Ratio instead of difference
  dist = "lognormal", 
  draws = 10000,
  seed = 98104
)
```

```{r}
#| echo: false
ratio_result[, c("contrast", "contrast_lower", "contrast_upper") := lapply(.SD, round2, 2), .SDcols = c("contrast", "contrast_lower", "contrast_upper")]
ratio_result[, c("contrast_se", "contrast_pvalue") := lapply(.SD, round2, 3), .SDcols = c("contrast_se", "contrast_pvalue")]
pretty_kable(ratio_result[, .(comparison, contrast, contrast_lower, contrast_upper, 
                           contrast_se, contrast_pvalue)])
```

# Advanced Examples

## Working with Multiple Comparisons

The real power of this function, besides not relying on parametric assumptions, is that you can easily batch process comparisons. For example, the following code will compare the death rates for different demographics in Megalopolis compared to Smallville.

### Table of Mortality Rates per 100,000
```{r}
#| warning: false
#| message: false
# Multiple demographic comparisons
multi_data <- data.table(
  demographic = c("Age 65+", "Age 25-64", "Female", "Male"),
  smallville_rate = c(2100, 420, 580, 720),
  smallville_lower = c(1950, 390, 540, 680),
  smallville_upper = c(2260, 455, 625, 765),
  megalopolis_rate = c(2250, 445, 615, 750),
  megalopolis_lower = c(2110, 415, 585, 715),
  megalopolis_upper = c(2400, 480, 650, 790)
)

```

```{r}
#| echo: false
pretty_kable(multi_data)
```

### Table of Mortality Rate Ratios

```{r}
#| warning: false
#| message: false
multi_result <- propagate_uncertainty(
  ph.estimates = multi_data,
  comp_mean_col = "megalopolis_rate",
  comp_lower_col = "megalopolis_lower",
  comp_upper_col = "megalopolis_upper",
  ref_mean_col = "smallville_rate", 
  ref_lower_col = "smallville_lower",
  ref_upper_col = "smallville_upper",
  contrast_fn = function(x, y) x / y, # The critical change
  dist = "lognormal",
  draws = 10000,
  seed = 98104
)
```

```{r}
#| echo: false
multi_result[, c("contrast", "contrast_lower", "contrast_upper") := lapply(.SD, round2, 2), .SDcols = c("contrast", "contrast_lower", "contrast_upper")]
multi_result[, c("contrast_se", "contrast_pvalue") := lapply(.SD, round2, 3), .SDcols = c("contrast_se", "contrast_pvalue")]
pretty_kable(multi_result[, .(demographic, contrast, contrast_lower, contrast_upper, 
                           contrast_se, contrast_pvalue)])
```

## Handling Exponentiated Regression Results

If you have odds ratios or rate ratios from regression models, you could convert them back to the log scale, but this is annoying and prone to error:

```{r}
#| warning: false
#| message: false
# Example: Odds ratios from logistic regression (the hard way)
or_data <- data.table(
  factor = "Urban vs Rural",
  urban_or = 1.45,      # Odds ratio
  urban_se_log = 0.12,  # Standard error on LOG scale  
  rural_or = 1.0,       # Reference (always 1.0)
  rural_se_log = 0      # Reference has no uncertainty
)

# Convert back to log scale for calculation
or_data[, urban_log := log(urban_or)]
or_data[, rural_log := log(rural_or)] 

# Calculate log ratio, then exponentiate
log_result <- propagate_uncertainty(
  ph.estimates = or_data,
  comp_mean_col = "urban_log",
  comp_se_col = "urban_se_log", 
  ref_mean_col = "rural_log",
  ref_se_col = "rural_se_log",
  contrast_fn = function(x, y) exp(x - y),  # Difference on log scale, then exp()
  dist = "normal",                          # Normal on log scale
  se_scale = "log",                         # SE is on log scale
  draws = 10000,
  seed = 98104
)
```

This works, but using `propagate_uncertainty()` directly with `dist = "lognormal"` is much easier for most cases.

# Practical Applications

The `propagate_uncertainty()` function is particularly valuable for:

**Comparing Pre-existing Estimates**: When comparing health indicators between demographic groups or geographic areas from summary estimates such as those from [CHI](https://kingcounty.gov/chi):

-   Life expectancy differences between racial/ethnic groups
-   Age-adjusted mortality rate comparisons\
-   Hospitalization rate ratios

**Data Requests**: When stakeholders want to know if differences between groups are statistically significant, particularly for indicators with asymmetric confidence intervals.

**Death Reports and Special Analyses**: When examining mortality trends or comparing rates across populations where traditional methods would give incorrect uncertainty estimates.

**Any Analysis Involving Age-Adjusted Rates**: Since age-adjusted rates typically have asymmetric confidence intervals due to the Fay-Feuer method or small counts in some age groups.

# Conclusion

Uncertainty propagation is a crucial but often overlooked aspect of comparing health indicators. While traditional mathematical formulas work well for simple means and proportions, they fail for some of the complex indicators we commonly use in public health.

The `propagate_uncertainty()` function provides a robust Monte Carlo solution that:

-   Works regardless of the underlying distributions
-   Properly handles asymmetric confidence intervals\
-   Automatically captures the correct uncertainty propagation
-   Provides both point estimates and hypothesis tests

By using this function, you can confidently compare health indicators while properly accounting for uncertainty, leading to more accurate and defensible conclusions in your analyses.

Remember: if your confidence intervals aren't roughly symmetric around your point estimates, traditional formulas will give you incorrect results. When in doubt, use `propagate_uncertainty()` - it will give you the right answer whether your distributions are normal or not.

-- *`r paste0('Updated ', format(Sys.time(), '%B %d, %Y'), ' (rads v', packageVersion('rads'), ')')`*
